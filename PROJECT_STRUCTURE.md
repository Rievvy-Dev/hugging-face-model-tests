_# ğŸ“ Estrutura Final do Projeto

## OrganizaÃ§Ã£o Corrigida

A estrutura foi organizada para respeitar a **metodologia de 5 estÃ¡gios**:

```
.
â”œâ”€â”€ ğŸ“„ README.md                       â† LEIA ISTO PRIMEIRO!
â”œâ”€â”€ ğŸ“„ QUICK_COMMANDS.md               â† Comandos rÃ¡pidos
â”œâ”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“„ requirements-ml.txt              
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ STAGE 0: Dataset
â”‚   â””â”€â”€ ğŸ prepare_scielo_dataset.py   (gera abstracts_scielo.csv)
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ STAGE 1: AvaliaÃ§Ã£o Inicial (6 modelos Ã— 4 datasets)
â”‚   â”œâ”€â”€ ğŸ models-test.py              (5 modelos primÃ¡rios)
â”‚   â”œâ”€â”€ ğŸ evaluate_quickmt.py         (6Âº modelo)
â”‚   â””â”€â”€ ğŸ“Š evaluation_results/
â”‚       â””â”€â”€ translation_metrics_all.csv â† RESULTADO
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ STAGE 2: SeleÃ§Ã£o dos Melhores
â”‚   â””â”€â”€ ğŸ choose_best_model.py        (Top 2 ranking)
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ STAGE 3: PreparaÃ§Ã£o de Dados
â”‚   â””â”€â”€ ğŸ“¦ finetuning/abstracts-datasets/
â”‚       â”œâ”€â”€ scielo_abstracts_train.csv  (200k)
â”‚       â”œâ”€â”€ scielo_abstracts_val.csv    (20k)
â”‚       â””â”€â”€ scielo_abstracts_test.csv   (20k)
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ STAGE 4: Fine-tuning
â”‚   â””â”€â”€ ğŸ finetuning/finetune_selected_models.py
â”‚       â””â”€â”€ ğŸ“‚ models/finetuned-scielo/
â”‚           â”œâ”€â”€ helena/
â”‚           â””â”€â”€ m2m100/
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ STAGE 5: AvaliaÃ§Ã£o Final & ComparaÃ§Ã£o
â”‚   â”œâ”€â”€ ğŸ finetuning/select_and_test_models.py
â”‚   â”œâ”€â”€ ğŸ compare_results.py
â”‚   â”œâ”€â”€ ğŸ“Š evaluation_results/
â”‚   â”‚   â”œâ”€â”€ scielo_before_finetuning.csv
â”‚   â”‚   â””â”€â”€ scielo_after_finetuning.csv
â”‚   â””â”€â”€ ğŸ“„ SCIENCE_EVALUATION_REPORT.txt â† RESULTADO FINAL
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ MÃ³dulos Core
â”‚   â””â”€â”€ ğŸ“¦ finetuning/
â”‚       â”œâ”€â”€ config.py              (configuraÃ§Ãµes)
â”‚       â”œâ”€â”€ models.py              (carregar/salvar)
â”‚       â”œâ”€â”€ datasets.py            (preparaÃ§Ã£o dados)
â”‚       â”œâ”€â”€ metrics.py             (BLEU, chr-F, COMET, BERTScore)
â”‚       â”œâ”€â”€ evaluate.py            (avaliaÃ§Ã£o com progresso)
â”‚       â”œâ”€â”€ trainer.py             (Seq2SeqTrainer)
â”‚       â”œâ”€â”€ compare.py             (comparaÃ§Ã£o)
â”‚       â”œâ”€â”€ io_utils.py            (utilitÃ¡rios)
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ Checkpoints (para resumir se interrompido)
â”‚   â””â”€â”€ checkpoints/
â”‚       â”œâ”€â”€ training/
â”‚       â””â”€â”€ evaluation/
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ Resultados de AvaliaÃ§Ã£o Anterior
â”‚   â””â”€â”€ evaluation_results/
â”‚       â”œâ”€â”€ translation_metrics_all.csv
â”‚       â”œâ”€â”€ <modelo>.csv
â”‚       â””â”€â”€ [scielo_before/after_finetuning.csv]
â”‚
â””â”€â”€ ğŸ“Š Dataset Completo
    â””â”€â”€ abstracts_scielo.csv   (2.7M exemplos)
```

---

## âœ… O que foi Restaurado/Mantido

| Arquivo | Status | Motivo |
|---------|--------|--------|
| `models-test.py` | âœ… Mantido | STAGE 1 - avalia 5 modelos |
| `evaluate_quickmt.py` | âœ… Mantido | STAGE 1 - avalia 6Âº modelo |
| `choose_best_model.py` | âœ… Mantido | STAGE 2 - seleciona top 2 |
| `prepare_scielo_dataset.py` | âœ… Mantido | STAGE 0 - gera dataset |
| `finetune_and_evaluate.py` | âœ… Mantido | Pipeline integrado (opcional) |
| `compare_results.py` | âœ… Mantido | STAGE 5 - relatÃ³rio |
| `finetuning/select_and_test_models.py` | âœ… Novo | STAGE 3, 5 - testa em SciELO |
| `finetuning/finetune_selected_models.py` | âœ… Novo | STAGE 4 - fine-tuning |

---

## ğŸ“ Metodologia Simplificada

```
1ï¸âƒ£  Buscar + Separar dados SciELO
    â”œâ”€ prepare_scielo_dataset.py
    â””â”€ select_and_test_models.py (cria train/val/test)

2ï¸âƒ£  Testar modelos base em SciELO
    â””â”€ select_and_test_models.py (gera scielo_before_finetuning.csv)

3ï¸âƒ£  Fine-tune dos 2 modelos
    â””â”€ finetune_selected_models.py (salva checkpoints)

4ï¸âƒ£  Avaliar fine-tuned em SciELO
    â””â”€ select_and_test_models.py --test_finetuned

5ï¸âƒ£  Comparar base vs fine-tuned
    â””â”€ compare_results.py (gera relatÃ³rio)
```

---

## ğŸ¯ Cronograma de ExecuÃ§Ã£o

```bash
# 1. Preparar dataset
python prepare_scielo_dataset.py                           # ~1 min

# 2. Separar dados (automÃ¡tico na prÃ³xima etapa)
# (vai ser criado por select_and_test_models.py)

# 3. Testar modelos base em SciELO
python finetuning/select_and_test_models.py --skip_prepare # ~3 horas

# 4. Fine-tuning (2 modelos Ã— 5 Ã©pocas)
python finetuning/finetune_selected_models.py --skip_prepare  # ~8-12 horas

# 5. Avaliar e gerar relatÃ³rio
python finetuning/select_and_test_models.py --test_both --skip_prepare  # ~3 horas
python compare_results.py                                 # ~10 seg

# Total: ~15-20 horas (com GPU)
```

---

## ğŸ”‘ Pontos-Chave da Metodologia

### âœ… Dados nÃ£o se sobrepÃµem
- Train: 200k (74% dos 240k)
- Val: 20k (8%)
- Test: 20k (8% - MESMOS usados em STAGE 1!)

### âœ… Checkpoints permitem retomar
- STAGE 4: Checkpoints salvos a cada 1/5 da Ã©poca
- STAGE 5: CSV armazenam estados intermediÃ¡rios

### âœ… ComparaÃ§Ã£o justa
- STAGE 1: Testar modelos base nos 20k dados
- STAGE 5: Testar modelos fine-tuned nos MESMOS 20k dados
- Delta de BLEU mostra real melhoria

### âœ… MÃ©tricas compromete
- BLEU + chr-F (rÃ¡pido, jÃ¡ calculado)
- COMET + BERTScore F1 (neural, mais preciso, mas lento)
- Score composto (0.30Ã—BLEU + 0.25Ã—chr-F + 0.25Ã—COMET + 0.20Ã—BS)

---

## ğŸ“š Para Entender Melhor

1. **Leia primeiro**: [README.md](README.md) - explicaÃ§Ã£o detalhada de cada estÃ¡gio
2. **Comandos rÃ¡pidos**: [QUICK_COMMANDS.md](QUICK_COMMANDS.md) - copy-paste dos comandos
3. **Ver configuraÃ§Ãµes**: `finetuning/config.py` - ajustar hiperparÃ¢metros
4. **Help dos scripts**:
   ```bash
   python finetuning/finetune_selected_models.py --help
   python finetuning/select_and_test_models.py --help
   ```

---

**VersÃ£o**: 3.0 | **Data**: Fevereiro 2026 | **Status**: âœ… Pronto para usar
