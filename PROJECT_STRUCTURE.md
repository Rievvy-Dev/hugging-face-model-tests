# Estrutura do Projeto

## OrganizaÃ§Ã£o por EstÃ¡gio

A estrutura segue a **metodologia de 5 estÃ¡gios** do pipeline de avaliaÃ§Ã£o e fine-tuning.

```
.
â”œâ”€â”€ ğŸ“„ README.md                               â† DocumentaÃ§Ã£o principal
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md                    â† Este arquivo
â”œâ”€â”€ ğŸ“„ QUICK_COMMANDS.md                       â† Comandos rÃ¡pidos
â”œâ”€â”€ ğŸ“„ requirements.txt                        â† DependÃªncias gerais
â”œâ”€â”€ ğŸ“„ requirements-ml.txt                     â† DependÃªncias ML
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ STAGE 0: Dataset
â”‚   â””â”€â”€ ğŸ prepare_scielo_dataset.py           Gera abstracts_scielo.csv (2.7M exemplos)
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ STAGE 1: AvaliaÃ§Ã£o Inicial (6 modelos Ã— 4 datasets)
â”‚   â”œâ”€â”€ ğŸ models-test.py                     Avalia 5 modelos primÃ¡rios
â”‚   â”œâ”€â”€ ğŸ evaluate_quickmt.py                Avalia 6Âº modelo (QuickMT)
â”‚   â”œâ”€â”€ ğŸ compute_neural_metrics.py          Calcula COMET e BERTScore
â”‚   â””â”€â”€ ğŸ“Š evaluation_results/
â”‚       â”œâ”€â”€ translation_metrics_all.csv        Consolidado
â”‚       â”œâ”€â”€ Helsinki-NLP_opus-mt-tc-big-en-pt.csv
â”‚       â”œâ”€â”€ Narrativa_mbart-large-50-finetuned-opus-en-pt-translation.csv
â”‚       â”œâ”€â”€ unicamp-dl_translation-en-pt-t5.csv
â”‚       â”œâ”€â”€ VanessaSchenkel_unicamp-finetuned-en-to-pt-dataset-ted.csv
â”‚       â”œâ”€â”€ danhsf_m2m100_418M-finetuned-kde4-en-to-pt_BR.csv
â”‚       â””â”€â”€ quickmt_quickmt-en-pt.csv
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ STAGE 2: SeleÃ§Ã£o do Modelo
â”‚   â”œâ”€â”€ ğŸ choose_best_model.py               Ranking por score composto
â”‚   â””â”€â”€ ğŸ show_model_configs.py              Exibe configuraÃ§Ãµes dos modelos
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ STAGE 3: PreparaÃ§Ã£o de Dados (Dataset Compacto)
â”‚   â””â”€â”€ ğŸ“¦ finetuning/abstracts-datasets/
â”‚       â”œâ”€â”€ abstracts_scielo.csv               Corpus completo (2.7M)
â”‚       â”œâ”€â”€ scielo_abstracts_train.csv         18.000 exemplos (treino)
â”‚       â”œâ”€â”€ scielo_abstracts_val.csv            2.000 exemplos (validaÃ§Ã£o)
â”‚       â””â”€â”€ scielo_abstracts_test.csv           5.000 exemplos (teste)
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ STAGE 4: Fine-tuning (unicamp-dl/translation-en-pt-t5)
â”‚   â”œâ”€â”€ ğŸ finetuning/finetune_selected_models.py   Script de fine-tuning
â”‚   â””â”€â”€ â­ unicamp-t5/unicamp-t5/                    Modelo fine-tuned
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ generation_config.json
â”‚       â”œâ”€â”€ model.safetensors                         Pesos do melhor modelo
â”‚       â”œâ”€â”€ tokenizer.json
â”‚       â”œâ”€â”€ tokenizer_config.json
â”‚       â”œâ”€â”€ spiece.model                              SentencePiece
â”‚       â”œâ”€â”€ special_tokens_map.json
â”‚       â”œâ”€â”€ checkpoint-12375/                         Epoch 11
â”‚       â””â”€â”€ checkpoint-13500/                         Epoch 12 (best)
â”‚           â”œâ”€â”€ model.safetensors
â”‚           â”œâ”€â”€ optimizer.pt
â”‚           â”œâ”€â”€ scheduler.pt
â”‚           â”œâ”€â”€ trainer_state.json                    Log completo
â”‚           â””â”€â”€ training_args.bin
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ STAGE 5: AvaliaÃ§Ã£o Final e ComparaÃ§Ã£o
â”‚   â”œâ”€â”€ ğŸ finetuning/select_and_test_models.py      Avalia base e fine-tuned
â”‚   â”œâ”€â”€ ğŸ“Š scielo_before_finetuning.csv               Baseline (BLEU=40.06)
â”‚   â”œâ”€â”€ ğŸ“Š scielo_after_finetuning_epoch_1.csv        Epoch 1
â”‚   â”œâ”€â”€ ğŸ“Š scielo_after_finetuning_epoch_11.csv       Epoch 11 (BLEU=45.51)
â”‚   â””â”€â”€ ğŸ“Š scielo_after_finetuning_epoch_12.csv       Epoch 12 (BLEU=45.51)
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ MÃ³dulos Core
â”‚   â”œâ”€â”€ ğŸ“¦ evaluation/                        MÃ³dulo de avaliaÃ§Ã£o (STAGE 1)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py                         ConfiguraÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ datasets.py                       Datasets pÃºblicos
â”‚   â”‚   â”œâ”€â”€ metrics.py                        MÃ©tricas
â”‚   â”‚   â”œâ”€â”€ models_loader.py                  Carregamento de modelos
â”‚   â”‚   â”œâ”€â”€ run.py                            ExecuÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ io_utils.py                       UtilitÃ¡rios I/O
â”‚   â”‚   â””â”€â”€ fill_missing_metrics.py           Preenchimento
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“¦ finetuning/                        MÃ³dulo de fine-tuning (STAGES 3-5)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py                          ConfiguraÃ§Ãµes centralizadas
â”‚       â”œâ”€â”€ models.py                          Carregamento/salvamento
â”‚       â”œâ”€â”€ data_utils.py                      PreparaÃ§Ã£o de dados
â”‚       â”œâ”€â”€ datasets.py                        Dataset handling
â”‚       â”œâ”€â”€ metrics.py                         BLEU, chrF, COMET, BERTScore
â”‚       â”œâ”€â”€ evaluate.py                        AvaliaÃ§Ã£o com progresso
â”‚       â”œâ”€â”€ trainer.py                         Seq2SeqTrainer + loop
â”‚       â”œâ”€â”€ compare.py                         ComparaÃ§Ã£o base vs fine-tuned
â”‚       â””â”€â”€ io_utils.py                        UtilitÃ¡rios I/O
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ Pipeline Integrado
â”‚   â””â”€â”€ ğŸ finetune_and_evaluate.py            Executa STAGES 1-5 automaticamente
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ Auxiliares
â”‚   â”œâ”€â”€ ğŸ check_gpu.py                       VerificaÃ§Ã£o de GPU
â”‚   â”œâ”€â”€ ğŸ split_scielo.py                    DivisÃ£o manual do dataset
â”‚   â”œâ”€â”€ ğŸ“‚ models-configs/                    ConfiguraÃ§Ãµes JSON
â”‚   â”‚   â”œâ”€â”€ helsink.json
â”‚   â”‚   â””â”€â”€ m2m100.json
â”‚   â”œâ”€â”€ ğŸ“‚ models/finetuned-scielo/           Fine-tunings anteriores
â”‚   â”‚   â””â”€â”€ helsinki/
â”‚   â””â”€â”€ ğŸ“‚ checkpoints/                       Checkpoints de controle
â”‚       â”œâ”€â”€ training/
â”‚       â””â”€â”€ evaluation/
â”‚
â””â”€â”€ ğŸ“¦ Arquivos de Modelo Compactado
    â””â”€â”€ unicamp-t5.zip                         Modelo fine-tuned compactado
```

---

## Arquivos Importantes

| Arquivo | EstÃ¡gio | DescriÃ§Ã£o |
|---------|---------|-----------|
| `scielo_before_finetuning.csv` | 5 | MÃ©tricas baseline: BLEU=40.06 |
| `scielo_after_finetuning_epoch_12.csv` | 5 | MÃ©tricas fine-tuned: BLEU=45.51 |
| `unicamp-t5/unicamp-t5/model.safetensors` | 4 | Pesos do melhor modelo |
| `unicamp-t5/unicamp-t5/checkpoint-13500/trainer_state.json` | 4 | Log completo de treinamento (12 epochs) |
| `evaluation_results/translation_metrics_all.csv` | 1 | Resultados de todos os 6 modelos |
| `finetuning/abstracts-datasets/scielo_abstracts_test.csv` | 3 | 5k exemplos de teste |

---

## Metodologia Resumida

```
1ï¸âƒ£  Avaliar 6 modelos em datasets pÃºblicos
    â””â”€ models-test.py + evaluate_quickmt.py

2ï¸âƒ£  Selecionar unicamp-dl/translation-en-pt-t5
    â””â”€ choose_best_model.py

3ï¸âƒ£  Preparar splits SciELO (18k treino, 2k val, 5k teste)
    â””â”€ select_and_test_models.py

4ï¸âƒ£  Fine-tuning na RTX 4050 (12 epochs, batch=8, grad_accum=2)
    â””â”€ finetune_selected_models.py â†’ unicamp-t5/unicamp-t5/

5ï¸âƒ£  Avaliar e comparar: BLEU 40.06 â†’ 45.51 (+13.6%)
    â””â”€ select_and_test_models.py --test_both
```
